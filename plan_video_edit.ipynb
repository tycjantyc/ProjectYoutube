{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dostaniesz zaraz transkrypt fragmentu podcastu z chwilami czasu, kiedy co jest mówione. Wybierz w których chwilach należy dodać zdjęcie/grafikę wygenerowaną przez AI oraz jakie inne zmiany edytorskie (wycięcie ciszy, powiększenie osoby mówiącej) dodać. Jeśli dodajesz grafikę to od razu wygeneruj prompt dla Dall-E 3, dzięku któremu można by uzyskać daną grafikę. Zadbaj o to, żeby film był jak najbardziej ciekawy i zajmujący. Swoją odpowiedź daj w formacie: Czas 1-Czas 2 - (opis zmiany lub \"Grafika AI -prompt:...\"). Oto Twój fragment transkryptu: \n",
      "I wake up in the morning and I want to reach for my phone, but I know that even if I were to crank up the brightness on that phone screen, it's not bright enough to trigger that cortisol spike and for me to be at my most alert and focus throughout the day and to optimize my sleep at night.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=key)\n",
    "\n",
    "\n",
    "f = open(\"basic_video.txt\", \"r\", encoding=\"utf-8\")\n",
    "basic_prompt = f.readline()\n",
    "\n",
    "f = open(\"system_video.txt\", \"r\", encoding=\"utf-8\")\n",
    "system_message = f.readline()\n",
    "\n",
    "print(basic_prompt)\n",
    "f = open(\"final_fragments/fragments1.txt\", \"r\", encoding=\"utf-8\")\n",
    "transcript = f.readlines()\n",
    "num = 0\n",
    "\n",
    "\n",
    "#COVERSATION HISTORY PREPARE\n",
    "conversation_history = [\n",
    "    {'role':'system', 'content': system_message},\n",
    "    {'role':'user', 'content': basic_prompt + transcript[num]}\n",
    "]\n",
    "\n",
    "print(transcript[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas 0:00-0:10 - Powiększenie osoby mówiącej\n",
      "Czas 0:10-0:12 - Grafika AI - prompt: \"A person reaching for a phone in the morning\"\n",
      "Czas 0:12-0:20 - Wycięcie ciszy\n",
      "Czas 0:20-0:30 - Powiększenie osoby mówiącej\n",
      "Czas 0:30-0:32 - Grafika AI - prompt: \"Bright phone screen with high brightness setting\"\n",
      "Czas 0:32-0:40 - Powiększenie osoby mówiącej\n"
     ]
    }
   ],
   "source": [
    "#FIRST BASE PROMPT\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=conversation_history\n",
    ")\n",
    "\n",
    "#ADD QUERY TO HISTORY\n",
    "conversation_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "\n",
    "#DISPLAY ANSWEAR\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
